import math

import torch


def positional_embedding(src_tokens):
    pass

def create_mask(lengths):
    pass
